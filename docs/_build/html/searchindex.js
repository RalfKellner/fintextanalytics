Search.setIndex({"docnames": ["autoapi/fintextanalytics/embeddingmodels/index", "autoapi/fintextanalytics/frequencymodels/index", "autoapi/fintextanalytics/index", "autoapi/fintextanalytics/utils/index", "autoapi/index", "changelog", "conduct", "contributing", "example", "index"], "filenames": ["autoapi/fintextanalytics/embeddingmodels/index.rst", "autoapi/fintextanalytics/frequencymodels/index.rst", "autoapi/fintextanalytics/index.rst", "autoapi/fintextanalytics/utils/index.rst", "autoapi/index.rst", "changelog.md", "conduct.md", "contributing.md", "example.ipynb", "index.md"], "titles": ["<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">fintextanalytics.embeddingmodels</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">fintextanalytics.frequencymodels</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">fintextanalytics</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">fintextanalytics.utils</span></code>", "API Reference", "Changelog", "Code of Conduct", "Contributing", "Example usage", "fintextanalytics"], "terms": {"freqanalyz": 1, "count_words_in_wordlist": 1, "token_list": 1, "wordlist": [0, 1, 8], "eword": [0, 1, 8], "count": [1, 3, 8], "occur": [1, 8], "word": [0, 1, 3], "from": [0, 1, 3, 6, 8], "list": [0, 1, 3, 8], "string": [0, 1, 3], "The": [0, 1, 3, 6, 7, 8], "can": [0, 1, 3, 7, 8], "gener": [0, 1, 4, 8], "raw": [1, 3, 8], "text": [1, 3, 9], "us": [0, 1, 3, 6, 7, 8], "text_preprocessor": [1, 3, 8], "function": [0, 1, 7, 8], "util": [1, 2, 4, 8], "howev": [0, 1], "you": [0, 1, 3, 7, 8, 9], "ar": [0, 1, 3, 6, 7], "free": [1, 6, 7], "preprocess": [1, 3], "token": [1, 3, 8], "like": 1, "A": [1, 3], "few": 1, "given": [1, 7], "default": [0, 1, 8], "initi": [1, 8], "instanc": [0, 1, 6], "also": [1, 8], "your": [1, 3, 7], "own": 1, "str": [0, 1, 3], "If": [0, 1, 7], "want": [0, 1, 3, 7, 8], "intern": [0, 1, 8], "must": [0, 1], "either": [0, 1], "sword": [0, 1], "gword": [0, 1], "esgword": [0, 1], "Or": [0, 1], "simpli": [0, 1], "provid": [0, 1, 8], "e": [0, 1, 3, 6, 8], "g": [0, 1, 3], "expect": [0, 1, 6, 8], "gdp": [0, 1], "revenu": [0, 1, 8], "pd": [1, 3, 8], "datafram": [0, 1, 3, 8], "static": [0, 1], "_load_default_wordlist": 1, "thi": [0, 1, 3, 4, 6, 7, 8, 9], "i": [0, 1, 3, 6, 7, 9], "made": [0, 1], "_validate_word": [0, 1], "frequencymodel": [2, 4], "__version__": 2, "sourc": [0, 1, 3], "simple_preprocess": 3, "combin": [3, 8], "strip_tag": 3, "gensim": [3, 8], "packag": [3, 8], "It": [3, 9], "remov": [3, 6], "number": [0, 3, 8], "tag": [3, 7], "other": [3, 6, 8], "symbol": 3, "scrape_10k_item": 3, "cik": 3, "accension_nbr": 3, "email": 3, "call": 3, "api": 3, "sec": 3, "http": [3, 9], "www": 3, "gov": 3, "scrape": 3, "10k": [0, 3, 8], "report": [3, 6, 9], "which": [0, 3, 6], "identifi": 3, "compani": [3, 8, 9], "": [3, 6, 7, 8], "accens": 3, "accension_nrb": 3, "address": [3, 6], "reveal": 3, "id": [0, 3, 8], "panda": [3, 8], "includ": [3, 6, 7, 8], "item": [3, 8], "1": [0, 3, 4, 6, 8], "1a": [3, 8], "3": [0, 3, 8], "7": 3, "7a": 3, "write_word_list": 3, "list_of_str": 3, "filenam": 3, "write": 3, "file": [0, 3], "locat": 3, "txt": 3, "end": 3, "none": [0, 3], "read_word_list": 3, "read": [3, 8], "write_pickl": 3, "obj": 3, "save": [0, 3], "an": [0, 3, 6], "object": 3, "pickl": [0, 3], "read_pickl": 3, "page": 4, "contain": [4, 8], "auto": 4, "document": [0, 3, 4], "fintextanalyt": [4, 5, 7, 8], "creat": [0, 4, 6, 7, 9], "sphinx": 4, "autoapi": 4, "first": [0, 5, 8], "releas": [5, 7, 9], "In": [0, 6, 8], "interest": [6, 9], "foster": 6, "open": [6, 7], "welcom": [6, 7], "environ": 6, "we": [6, 8], "contributor": 6, "maintain": 6, "make": [6, 7, 8], "particip": 6, "project": [6, 7, 9], "commun": [6, 8], "harass": 6, "experi": 6, "everyon": 6, "regardless": 6, "ag": 6, "bodi": 6, "size": 6, "disabl": 6, "ethnic": [6, 8], "gender": [6, 8], "ident": 6, "express": 6, "level": 6, "nation": [6, 8], "person": [6, 8], "appear": [6, 8], "race": 6, "religion": 6, "sexual": 6, "orient": 6, "exampl": [6, 9], "behavior": 6, "contribut": 6, "posit": 6, "inclus": [6, 8], "languag": 6, "Being": 6, "respect": 6, "differ": 6, "viewpoint": 6, "gracefulli": 6, "accept": [6, 8], "construct": 6, "critic": 6, "focus": [6, 8], "what": [6, 8], "best": 6, "show": 6, "empathi": 6, "toward": 6, "member": 6, "unaccept": 6, "imageri": 6, "unwelcom": 6, "attent": 6, "advanc": [6, 8], "troll": 6, "insult": 6, "derogatori": 6, "comment": 6, "polit": [6, 8], "attack": [6, 8], "public": [3, 6, 8], "privat": 6, "publish": 6, "inform": [3, 6, 8], "physic": 6, "electron": [6, 8], "without": 6, "explicit": 6, "permiss": 6, "could": [6, 8], "reason": [6, 8], "consid": [0, 6], "inappropri": 6, "profession": 6, "set": [0, 3, 6, 7], "clarifi": 6, "take": [3, 6, 8], "appropri": [6, 7], "fair": 6, "correct": 6, "action": [6, 8], "ani": [6, 7, 8], "have": [0, 6, 7, 8], "right": [6, 8], "edit": 6, "reject": 6, "commit": [6, 7], "wiki": 6, "issu": [6, 7, 8], "align": 6, "ban": 6, "temporarili": 6, "perman": 6, "thei": [3, 6, 7], "deem": 6, "threaten": 6, "offens": 6, "harm": [6, 8], "appli": 6, "both": 6, "within": 6, "space": [0, 6], "when": [0, 6, 7, 8], "individu": 6, "repres": [0, 6], "its": [3, 6, 7, 8, 9], "offici": [6, 7], "mail": 6, "post": [6, 7], "via": 6, "social": [6, 8], "media": [6, 8], "account": 6, "act": [6, 8], "appoint": 6, "onlin": 6, "offlin": 6, "event": [6, 8], "represent": 6, "mai": [6, 8], "further": [6, 8], "defin": [0, 6], "abus": 6, "otherwis": 6, "contact": 6, "team": 6, "review": 6, "investig": 6, "all": [6, 7, 8], "complaint": 6, "respond": 6, "wai": 6, "circumst": 6, "oblig": [6, 8], "confidenti": 6, "regard": [6, 8], "incid": 6, "detail": [6, 7], "specif": 6, "polici": [6, 8], "separ": 6, "who": 6, "do": [6, 8], "follow": [6, 8], "good": 6, "faith": 6, "face": 6, "temporari": 6, "repercuss": 6, "determin": 6, "leadership": 6, "adapt": 6, "coven": 6, "homepag": 6, "version": [6, 7], "4": [6, 8], "greatli": 7, "appreci": 7, "everi": 7, "littl": [7, 8], "bit": 7, "help": 7, "credit": [7, 8], "alwai": 7, "pleas": [7, 9], "oper": [7, 8], "system": 7, "name": [3, 7], "about": [7, 8], "local": [7, 8], "setup": 7, "might": [0, 7], "troubleshoot": 7, "step": 7, "reproduc": 7, "look": [0, 7, 8], "through": [7, 8], "github": [7, 9], "anyth": 7, "whoever": 7, "enhanc": 7, "never": 7, "enough": 7, "feel": 7, "part": [3, 7, 8], "doc": [7, 8], "docstr": 7, "even": 7, "web": 7, "blog": 7, "articl": 7, "propos": 7, "explain": 7, "how": 7, "would": 7, "work": 7, "keep": 7, "scope": 7, "narrow": 7, "possibl": 7, "easier": 7, "rememb": 7, "volunt": 7, "driven": 7, "readi": 7, "here": 7, "up": 7, "develop": [7, 8], "download": 7, "copi": [7, 8], "instal": 7, "poetri": 7, "git": [7, 9], "similar": [0, 7], "branch": 7, "chang": [7, 8], "checkout": 7, "b": 7, "bugfix": 7, "re": 7, "done": [0, 7], "check": [7, 9], "conform": 7, "format": 7, "requir": [7, 8], "pass": 7, "test": 7, "befor": [7, 8], "meet": 7, "should": [0, 7], "addit": [0, 7, 8], "add": [7, 8], "updat": 7, "current": [7, 8], "support": 7, "python": 7, "note": [0, 7, 9], "By": [7, 9], "agre": [7, 9], "abid": [7, 9], "term": [7, 9], "To": [], "import": 8, "print": 8, "0": [0, 3, 8], "analysi": 9, "pip": 9, "todo": [], "out": 9, "guidelin": 9, "code": 9, "conduct": [8, 9], "wa": 9, "ralf": 9, "kellner": 9, "under": 9, "mit": 9, "cookiecutt": 9, "py": 9, "pkg": 9, "templat": 9, "hello": [], "world": [], "fintextanalysi": [], "path": [], "src": [], "data": 8, "example_text": [], "r": [], "modulenotfounderror": [], "traceback": [], "most": [0, 8], "recent": [], "last": [], "cell": [], "line": [], "No": [], "modul": [], "risk": 8, "factor": 8, "busi": 8, "reput": 8, "result": 8, "financi": 8, "condit": 8, "stock": 8, "price": 8, "affect": 8, "whether": 8, "known": 8, "unknown": 8, "those": 8, "describ": [], "below": [], "one": [0, 8], "more": 8, "materi": 8, "time": [], "advers": 8, "becaus": [0, 8], "well": 8, "past": [], "perform": 8, "reliabl": [], "indic": [], "futur": 8, "investor": 8, "histor": [], "trend": [], "anticip": [], "period": [], "discuss": 8, "forward": [], "statement": 8, "section": [], "conjunct": [], "ii": [], "manag": [], "consolid": [], "accompani": [], "supplementari": 8, "form": [], "macroeconom": [], "industri": 8, "depend": 8, "significantli": 8, "global": 8, "region": 8, "econom": 8, "ha": 8, "sale": 8, "outsid": [], "major": [], "total": [], "net": [], "suppli": 8, "chain": 8, "larg": [], "complex": 8, "supplier": 8, "facil": 8, "manufactur": 8, "assembli": [], "site": [], "inflat": [], "slower": [], "growth": [], "recess": 8, "new": [], "increas": 8, "tariff": 8, "barrier": [], "trade": 8, "fiscal": [], "monetari": [], "tighter": [], "higher": [3, 8], "rate": 8, "high": [], "unemploy": [], "currenc": 8, "fluctuat": 8, "impact": 8, "consum": 8, "confid": [], "spend": [], "demand": 8, "product": 8, "servic": 8, "respons": [], "market": 8, "volatil": [], "neg": [], "real": [], "estat": [], "mortgag": [], "declin": [], "incom": [], "asset": [], "valu": [0, 8], "energi": [], "shortag": 8, "cost": 8, "labor": 8, "healthcar": [], "uncertainti": 8, "signific": 8, "contract": [], "logist": [], "distributor": [], "cellular": [], "network": [], "carrier": [], "channel": [], "partner": [], "potenti": 8, "effect": 8, "instabl": 8, "inabl": [], "obtain": 8, "financ": [], "purchas": 8, "insolv": [], "downturn": [], "lead": 8, "collect": 8, "receiv": 8, "failur": [], "deriv": 8, "counterparti": [], "institut": [], "limit": 8, "abil": 8, "debt": 8, "reduc": [0, 8], "liquid": [], "instrument": 8, "been": [0, 8], "covid": 8, "pandem": 8, "had": [], "continu": 8, "around": [], "prompt": [], "govern": 8, "unpreced": [], "measur": 8, "restrict": 8, "travel": [], "closur": [], "quarantin": [], "shelter": [], "place": 8, "order": [], "curtail": [], "activ": 8, "caus": 8, "disrupt": [], "taken": [], "mani": 8, "countri": 8, "dure": [], "cours": [], "certain": 0, "compon": 8, "experienc": [], "worldwid": 8, "safeti": 8, "area": 8, "appl": 8, "inc": 8, "monitor": [], "situat": [], "accord": [], "recommend": [], "relev": 8, "author": [], "extent": [], "remain": [], "uncertain": [], "control": 8, "trajectori": [], "durat": [], "emerg": 8, "variant": [], "avail": [0, 8], "distribut": [], "vaccin": [], "treatment": [], "imposit": [], "protect": 8, "economi": [], "execut": [], "strateg": [], "plan": [], "profit": [], "structur": [], "heighten": [], "disput": 8, "war": [], "terror": [], "natur": 8, "disast": 8, "health": 8, "accid": 8, "interrupt": 8, "commerc": 8, "custom": 8, "believ": [], "benefit": 8, "substanti": 8, "whole": [], "outsourc": [], "primarili": [], "asia": [], "china": [], "mainland": [], "india": [], "japan": [], "south": [], "korea": [], "taiwan": [], "vietnam": [], "conflict": [], "load_example_text": [3, 8], "25": [0, 8], "sent_detector": 3, "report2sent": [3, 8], "raw_text": [3, 8], "idx_start": [3, 8], "min_word": 3, "10": [3, 8], "max_word": 3, "100": [3, 8], "kwarg": 3, "split": 3, "sentenc": 3, "usual": 3, "k": 3, "int": [0, 3], "output": [0, 3], "index": [3, 8], "serv": 3, "start": [3, 8], "some": 3, "mayb": 3, "omit": 3, "too": 3, "short": 3, "lower": 3, "than": 3, "fals": [0, 3, 8], "usag": [0, 3], "long": [0, 3], "specifi": 3, "arbitrari": 3, "ad": [3, 8], "columnwis": [3, 8], "date": [3, 8], "just": 3, "purpos": 3, "demonstr": 3, "simpl": 8, "200": 8, "return": 8, "head": 8, "metadata": 8, "reputatio": 8, "2": 8, "materializ": 8, "o": 8, "forwa": 8, "prep_text": 8, "use_doc": 8, "true": [0, 8], "ot": [], "dbx": 0, "embeddinganaly": [0, 8], "doc_model_nam": 0, "fit_topic_model": [0, 8], "document_vector": 0, "ntopic_word": 0, "umap_arg": 0, "hdbscan_arg": 0, "rm_doc": 0, "cosine_threshold": 0, "5": [0, 8], "n_reduced_top": 0, "method": 0, "l2": [0, 8], "normal": [0, 8], "embed": 0, "vector": [0, 8], "dimens": 0, "umap": [0, 8], "dimension": [0, 8], "reduct": [0, 8], "model": 0, "hdbscan": [0, 8], "cluster": [0, 8], "topic": 0, "calcul": 0, "centroid": 0, "per": 0, "origin": 0, "cosin": [0, 8], "threshold": 0, "after": [0, 8], "process": 0, "finish": [0, 8], "two": 0, "algorithm": 0, "np": 0, "arrai": 0, "numpi": 0, "match": 0, "doc2vec": [0, 8], "dict": [0, 8], "dictionari": 0, "argument": 0, "boolean": 0, "train": [0, 8], "mean": 0, "delet": [0, 8], "fload": 0, "between": [0, 8], "abov": 0, "group": 0, "togeth": 0, "altern": 0, "logic": 0, "fix": 0, "desir": 0, "caution": 0, "low": 0, "merg": 0, "find_close_docs_to_word": [0, 8], "topn_docu": 0, "whose": 0, "close": 0, "specfici": 0, "tupl": 0, "second": [0, 8], "correspond": [0, 8], "find_close_words_to_doc": [0, 8], "topn_word": [0, 8], "find_close_topics_to_word": [0, 8], "topic_vector": [0, 8], "topn_top": [0, 8], "learn": 0, "find_close_topics_to_doc": [0, 8], "most_similar_word": [0, 8], "n_word": 0, "context": 0, "store": 0, "embeddinganalyz": 0, "load": 0, "previous": 0, "_find_topic_words_and_scor": 0, "nword": 0, "_create_topic_vector": 0, "cluster_label": 0, "_deduplicate_top": 0, "_reduce_topic_vector": 0, "_wordlist_prepar": 0, "print_info": 0, "_load_word_list": 0, "_validate_normed_vector": 0, "_l2_normal": 0, "_load_doc_model": 0, "model_nam": 0, "embeddingmodel": [2, 4, 8], "load_example_report": [3, 8], "row": 8, "x": 8, "column": 8, "sinc": 8, "2012": 8, "apple_10k_item": 8, "iter": 8, "each": 8, "idx": 8, "iterrow": 8, "report_sentences_prep_tmp": 8, "report_sentences_preprocess": 8, "accdat": 8, "concat": 8, "axi": 8, "els": 8, "map": 8, "docid": 8, "docid2idx": 8, "enumer": 8, "nthe": 8, "fact": 8, "item1a": 8, "31t17": 8, "07": 8, "19": 8, "000z": 8, "depen": 8, "p": 8, "For": 8, "ncontinu": 8, "sovereign": 8, "cr": 8, "cri": 8, "6": 8, "These": 8, "conditio": 8, "embed_analyz": 8, "get": 8, "embed_analzy": 8, "infer": 8, "doc_vec": 8, "doc_model": 8, "infer_vector": 8, "frame": 8, "closest": 8, "topn_doc": 8, "topn_doc_scor": 8, "let": 8, "u": [8, 9], "five": 8, "f": 8, "original_id": 8, "correspon": 8, "highest": 8, "loc": 8, "sum": 8, "49": 8, "found": 8, "word2vec": 8, "vocabulari": 8, "motiv": 8, "propon": 8, "discrimin": 8, "ungc": 8, "grandpar": 8, "honesti": 8, "human": 8, "minor": 8, "cobc": 8, "eeo": 8, "vacancyappreci": 8, "nondiscrimin": 8, "vestsballot": 8, "interlock": 8, "gai": 8, "lobbyist": 8, "grandchildren": 8, "lesbian": 8, "donat": 8, "perquisit": 8, "eicc": 8, "childbirth": 8, "sibl": 8, "homosexu": 8, "ilo": 8, "educ": 8, "ruggi": 8, "household": 8, "ballot": 8, "nephew": 8, "parachut": 8, "niec": 8, "bisexu": 8, "lgbt": 8, "spousal": 8, "stepchildren": 8, "webpag": 8, "transgend": 8, "ethic": 8, "steppar": 8, "marriag": 8, "seem": 8, "unit": 8, "length": 8, "clean": 8, "defect": 8, "unsaf": 8, "environment": 8, "properti": 8, "damag": 8, "injuri": 8, "subject": 8, "law": 8, "regul": 8, "antitrust": 8, "privaci": 8, "secur": 8, "advertis": 8, "bill": 8, "liabil": 8, "intellectu": 8, "ownership": 8, "infring": 8, "digit": 8, "platform": 8, "internet": 8, "telecommun": 8, "mobil": 8, "televis": 8, "film": 8, "content": 8, "third": 8, "parti": 8, "softwar": 8, "applic": 8, "employ": 8, "anticorrupt": 8, "export": 8, "foreign": 8, "exchang": 8, "cash": 8, "repatri": 8, "anti": 8, "monei": 8, "launder": 8, "invest": 8, "tax": 8, "wast": 8, "recycl": 8, "climat": 8, "epa": 8, "employe": 8, "stakehold": 8, "increasingli": 8, "consider": 8, "relat": 8, "greenhous": 8, "ga": 8, "emiss": 8, "civil": 8, "divers": 8, "equiti": 8, "sustain": 8, "type": 8, "frequent": 8, "intens": 8, "senctenc": 8, "paragraph": 8, "middl": 8, "exist": 8, "introduc": 8, "special": 8, "expos": 8, "complianc": 8, "oner": 8, "expens": 8, "goal": 8, "non": 8, "websit": 8, "press": 8, "fire": 8, "power": 8, "nuclear": 8, "plant": 8, "terrorist": 8, "hostil": 8, "ransomwar": 8, "cybersecur": 8, "beyond": 8, "Such": 8, "difficult": 8, "imposs": 8, "deliv": 8, "delai": 8, "ineffici": 8, "slowdown": 8, "outag": 8, "offer": 8, "sim_word": 8, "sim_word_scor": 8, "pollut": 8, "cleanup": 8, "remedi": 8, "hazard": 8, "829885": 8, "827046": 8, "812441": 8, "806115": 8, "767096": 8, "topn_word_scor": 8, "word_of_interest": 8, "n": 8, "inconsist": 8, "jurisdict": 8, "compli": 8, "incur": 8, "practic": 8, "noncompli": 8, "penalti": 8, "legal": 8, "2019": 8, "30t18": 8, "12": 8, "36": 8, "2020": 8, "29t18": 8, "06": 8, "2022": 8, "27t18": 8, "01": 8, "14": 8, "regulatori": 8, "announc": 8, "notic": 8, "abl": 8, "mitig": 8, "although": 8, "program": 8, "procedur": 8, "design": 8, "satisfi": 8, "assur": 8, "prevent": 8, "violat": 8, "claim": 8, "top": 8, "topic_word": 8, "len": 8, "20": 8, "17": 8, "demeanor": 8, "commerci": 8, "wit": 8, "conting": 8, "elsewher": 8, "cautionari": 8, "herein": 8, "caption": 8, "unassert": 8, "repurchas": 8, "ncib": 8, "dividend": 8, "buyback": 8, "equat": 8, "repay": 8, "equival": 8, "tcj": 8, "topn_topic_scor": 8, "9": 8, "16": 8, "13": 8, "8": 8, "063409": 8, "036895": 8, "027610": 8, "152109": 8, "138078": 8, "103929": 8, "021987": 8, "016028": 8, "007840": 8, "173058": 8, "122766": 8, "119503": 8, "201616": 8, "129706": 8, "080976": 8, "topn_doc_top": 8, "topn_doc_topic_scor": 8, "With": 8, "common": 8, "understand": [8, 9], "mostli": 8, "doc_idx_start": 8, "doc_idx_end": 8, "250": 8, "top_top": 8, "value_count": 8, "wiht": 8, "mask": 8, "corresponding_docid": 8, "protectionist": 8, "protection": 8, "embargo": 8, "constrict": 8, "censorship": 8, "retaliatori": 8, "retali": 8, "hyperinfl": 8, "expropri": 8, "dampen": 8, "waver": 8, "auster": 8, "oversea": 8, "calam": 8, "blockag": 8, "boycott": 8, "diplomat": 8, "unrest": 8, "unpredict": 8, "portion": 8, "earn": 8, "corrupt": 8, "competit": 8, "associ": 8, "duti": 8, "dollar": 8, "versu": 8, "margin": 8, "antidump": 8, "european": 8, "restructur": 8, "effort": 8, "sever": 8, "euro": 8, "weaken": 8, "rel": 8, "denomin": 8, "rais": 8, "convers": 8, "strengthen": 8, "while": 8, "benefici": 8, "loss": 8, "therebi": 8, "addition": 8, "thu": 8, "gross": 8, "exposur": 8, "unfavor": 8, "proceed": 8, "tbd": 9, "see": 9, "better": 9, "com": 9, "ralfkelln": 9}, "objects": {"": [[2, 0, 0, "-", "fintextanalytics"]], "fintextanalytics": [[2, 1, 1, "", "__version__"], [0, 0, 0, "-", "embeddingmodels"], [1, 0, 0, "-", "frequencymodels"], [3, 0, 0, "-", "utils"]], "fintextanalytics.embeddingmodels": [[0, 2, 1, "", "EmbeddingAnalyer"], [0, 1, 1, "", "dbx"]], "fintextanalytics.embeddingmodels.EmbeddingAnalyer": [[0, 3, 1, "", "_create_topic_vectors"], [0, 3, 1, "", "_deduplicate_topics"], [0, 3, 1, "", "_find_topic_words_and_scores"], [0, 3, 1, "", "_l2_normalize"], [0, 3, 1, "", "_load_doc_model"], [0, 3, 1, "", "_load_word_list"], [0, 3, 1, "", "_reduce_topic_vectors"], [0, 3, 1, "", "_validate_normed_vectors"], [0, 3, 1, "", "_validate_words"], [0, 3, 1, "", "_wordlist_prepared"], [0, 3, 1, "", "find_close_docs_to_words"], [0, 3, 1, "", "find_close_topics_to_docs"], [0, 3, 1, "", "find_close_topics_to_words"], [0, 3, 1, "", "find_close_words_to_docs"], [0, 3, 1, "", "fit_topic_model"], [0, 3, 1, "", "load"], [0, 3, 1, "", "most_similar_words"], [0, 3, 1, "", "save"]], "fintextanalytics.frequencymodels": [[1, 2, 1, "", "FreqAnalyzer"]], "fintextanalytics.frequencymodels.FreqAnalyzer": [[1, 3, 1, "", "_load_default_wordlists"], [1, 3, 1, "", "_validate_words"], [1, 3, 1, "", "count_words_in_wordlist"]], "fintextanalytics.utils": [[3, 4, 1, "", "load_example_reports"], [3, 4, 1, "", "load_example_text"], [3, 4, 1, "", "read_pickle"], [3, 4, 1, "", "read_word_list"], [3, 4, 1, "", "report2sentences"], [3, 4, 1, "", "scrape_10k_items"], [3, 1, 1, "", "sent_detector"], [3, 4, 1, "", "text_preprocessor"], [3, 4, 1, "", "write_pickle"], [3, 4, 1, "", "write_word_list"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"fintextanalyt": [0, 1, 2, 3, 9], "frequencymodel": 1, "modul": [0, 1, 3], "content": [0, 1, 2, 3], "class": [0, 1], "paramet": [0, 1, 3], "return": [0, 1, 3], "submodul": 2, "packag": 2, "util": 3, "function": 3, "paramt": 3, "api": 4, "refer": 4, "changelog": 5, "v0": 5, "1": 5, "0": 5, "19": 5, "03": 5, "2023": 5, "code": [6, 7], "conduct": [6, 7], "our": 6, "pledg": 6, "standard": 6, "respons": 6, "scope": 6, "enforc": 6, "attribut": [0, 3, 6], "contribut": [7, 9], "type": 7, "report": [7, 8], "bug": 7, "fix": 7, "implement": 7, "featur": 7, "write": 7, "document": [7, 8], "submit": 7, "feedback": 7, "get": 7, "start": 7, "pull": 7, "request": 7, "guidelin": 7, "exampl": 8, "usag": [8, 9], "instal": 9, "licens": 9, "credit": 9, "preprocess": 8, "some": 8, "text": 8, "split": 8, "sentenc": 8, "embeddingmodel": 0, "load": 8, "them": 8, "analysi": 8, "search": 8, "whose": 8, "mean": 8, "i": 8, "close": 8, "certain": 8, "word": 8, "find": 8, "similar": 8, "context": 8, "creat": 8, "topic": 8, "accord": 8, "top2vec": 8, "model": 8, "idea": 8, "which": 8, "ar": 8}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Changelog": [[5, "changelog"]], "v0.1.0 (19/03/2023)": [[5, "v0-1-0-19-03-2023"]], "Code of Conduct": [[6, "code-of-conduct"], [7, "code-of-conduct"]], "Our Pledge": [[6, "our-pledge"]], "Our Standards": [[6, "our-standards"]], "Our Responsibilities": [[6, "our-responsibilities"]], "Scope": [[6, "scope"]], "Enforcement": [[6, "enforcement"]], "Attribution": [[6, "attribution"]], "Contributing": [[7, "contributing"], [9, "contributing"]], "Types of Contributions": [[7, "types-of-contributions"]], "Report Bugs": [[7, "report-bugs"]], "Fix Bugs": [[7, "fix-bugs"]], "Implement Features": [[7, "implement-features"]], "Write Documentation": [[7, "write-documentation"]], "Submit Feedback": [[7, "submit-feedback"]], "Get Started!": [[7, "get-started"]], "Pull Request Guidelines": [[7, "pull-request-guidelines"]], "Example usage": [[8, "example-usage"]], "Preprocess some text": [[8, "preprocess-some-text"]], "Split a document into preprocessed sentences": [[8, "split-a-document-into-preprocessed-sentences"]], "Load example reports and preprocess them for analysis": [[8, "load-example-reports-and-preprocess-them-for-analysis"]], "Search for documents whose meaning is close to the meaning of certain words": [[8, "search-for-documents-whose-meaning-is-close-to-the-meaning-of-certain-words"]], "Find word with similar meaning or context": [[8, "find-word-with-similar-meaning-or-context"]], "Search for words whose meaning is close to documents": [[8, "search-for-words-whose-meaning-is-close-to-documents"]], "Creating topics according to the top2vec model idea": [[8, "creating-topics-according-to-the-top2vec-model-idea"]], "Find topics which are close to the meaning of words": [[8, "find-topics-which-are-close-to-the-meaning-of-words"]], "Find topics for documents": [[8, "find-topics-for-documents"]], "fintextanalytics.embeddingmodels": [[0, "module-fintextanalytics.embeddingmodels"]], "Module Contents": [[0, "module-contents"], [1, "module-contents"], [3, "module-contents"]], "Classes": [[0, "classes"], [1, "classes"]], "Attributes": [[0, "attributes"], [3, "attributes"]], "Parameters:": [[0, "parameters"], [0, "id1"], [0, "id2"], [0, "id4"], [0, "id6"], [0, "id8"], [1, "parameters"], [3, "parameters"], [3, "id4"], [3, "id6"], [3, "id8"], [3, "id10"], [3, "id12"]], "Returns:": [[0, "returns"], [0, "id3"], [0, "id5"], [0, "id7"], [0, "id9"], [1, "returns"], [3, "returns"], [3, "id3"], [3, "id5"], [3, "id7"], [3, "id9"], [3, "id11"], [3, "id13"]], "fintextanalytics.frequencymodels": [[1, "module-fintextanalytics.frequencymodels"]], "fintextanalytics": [[2, "module-fintextanalytics"], [9, "fintextanalytics"]], "Submodules": [[2, "submodules"]], "Package Contents": [[2, "package-contents"]], "fintextanalytics.utils": [[3, "module-fintextanalytics.utils"]], "Functions": [[3, "functions"]], "Paramters:": [[3, "paramters"]], "API Reference": [[4, "api-reference"]], "Installation": [[9, "installation"]], "Usage": [[9, "usage"]], "License": [[9, "license"]], "Credits": [[9, "credits"]]}, "indexentries": {"embeddinganalyer (class in fintextanalytics.embeddingmodels)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer"]], "_create_topic_vectors() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._create_topic_vectors"]], "_deduplicate_topics() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._deduplicate_topics"]], "_find_topic_words_and_scores() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._find_topic_words_and_scores"]], "_l2_normalize() (fintextanalytics.embeddingmodels.embeddinganalyer static method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._l2_normalize"]], "_load_doc_model() (fintextanalytics.embeddingmodels.embeddinganalyer static method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._load_doc_model"]], "_load_word_list() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._load_word_list"]], "_reduce_topic_vectors() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._reduce_topic_vectors"]], "_validate_normed_vectors() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._validate_normed_vectors"]], "_validate_words() (fintextanalytics.embeddingmodels.embeddinganalyer static method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._validate_words"]], "_wordlist_prepared() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer._wordlist_prepared"]], "dbx (in module fintextanalytics.embeddingmodels)": [[0, "fintextanalytics.embeddingmodels.dbx"]], "find_close_docs_to_words() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer.find_close_docs_to_words"]], "find_close_topics_to_docs() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer.find_close_topics_to_docs"]], "find_close_topics_to_words() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer.find_close_topics_to_words"]], "find_close_words_to_docs() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer.find_close_words_to_docs"]], "fintextanalytics.embeddingmodels": [[0, "module-fintextanalytics.embeddingmodels"]], "fit_topic_model() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer.fit_topic_model"]], "load() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer.load"]], "module": [[0, "module-fintextanalytics.embeddingmodels"], [1, "module-fintextanalytics.frequencymodels"], [2, "module-fintextanalytics"], [3, "module-fintextanalytics.utils"]], "most_similar_words() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer.most_similar_words"]], "save() (fintextanalytics.embeddingmodels.embeddinganalyer method)": [[0, "fintextanalytics.embeddingmodels.EmbeddingAnalyer.save"]], "freqanalyzer (class in fintextanalytics.frequencymodels)": [[1, "fintextanalytics.frequencymodels.FreqAnalyzer"]], "_load_default_wordlists() (fintextanalytics.frequencymodels.freqanalyzer static method)": [[1, "fintextanalytics.frequencymodels.FreqAnalyzer._load_default_wordlists"]], "_validate_words() (fintextanalytics.frequencymodels.freqanalyzer static method)": [[1, "fintextanalytics.frequencymodels.FreqAnalyzer._validate_words"]], "count_words_in_wordlist() (fintextanalytics.frequencymodels.freqanalyzer method)": [[1, "fintextanalytics.frequencymodels.FreqAnalyzer.count_words_in_wordlist"]], "fintextanalytics.frequencymodels": [[1, "module-fintextanalytics.frequencymodels"]], "__version__ (in module fintextanalytics)": [[2, "fintextanalytics.__version__"]], "fintextanalytics": [[2, "module-fintextanalytics"]], "fintextanalytics.utils": [[3, "module-fintextanalytics.utils"]], "load_example_reports() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.load_example_reports"]], "load_example_text() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.load_example_text"]], "read_pickle() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.read_pickle"]], "read_word_list() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.read_word_list"]], "report2sentences() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.report2sentences"]], "scrape_10k_items() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.scrape_10k_items"]], "sent_detector (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.sent_detector"]], "text_preprocessor() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.text_preprocessor"]], "write_pickle() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.write_pickle"]], "write_word_list() (in module fintextanalytics.utils)": [[3, "fintextanalytics.utils.write_word_list"]]}})